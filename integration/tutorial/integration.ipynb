{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RISE Camp Capstone Exercise\n",
    "\n",
    "In this exercise, you will see how many of the projects you've learned about in the last couple days fit together. Those of you who attended last year's RISE Camp will remember the Pong integration exercise that trained an RL policy in Ray and deployed it in Clipper. Today's version of Pong is more feature rich: We take advantage of Flor's experiment tracking and WAVE's encryption capabilities, in addition to leveraging a new Clipper deployment model and RLlib's policies.\n",
    "\n",
    "We will train three ML models in this exercise: The first two models will use [imitation learning](https://blog.statsbot.co/introduction-to-imitation-learning-32334c3b1e7a) to learn how to play Pong, and the third will train a reinforcement learning policy using RLlib and Ray. Flor will track the training processes for all three models. We will also encrypt each one of these models with WAVE and deploy & serve the models in Clipper.\n",
    "\n",
    "For those of you unfamiliar with imitation learning, the approach is simple. We previously recorded the actions of humans playing Pong. The model we are buildling is a logitic regression classifier that selects a paddle action (up, down, or stay) based on the current location, velocity, and trajectory of the ball.\n",
    "\n",
    "Finally, you'll play a game (or more!) against each of the three models. We'll aggregate the results to see which model performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python compatibility imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import gym\n",
    "import pong_py\n",
    "import cloudpickle\n",
    "\n",
    "# ray imports\n",
    "import ray\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents import ppo\n",
    "\n",
    "import flor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Flor metadata for the notebook\n",
    "flor.setNotebookName('integration.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a separate notebook, we have set up a WAVE client and defined some helper functions that we'll use below. Feel free to look at the `wave-setup.ipynb` file in this directory if you'd like to dig in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run wave-setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call Wave helper function to create granting and receiving entities\n",
    "orgEntity, recipientEntity = createWaveEntities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imitation Learning\n",
    "\n",
    "## Model Training\n",
    "\n",
    "First, we're going to define three Flor functions---`preproc_imitation`, `train_imitation_model`, and `encrypt_model`, which clean the input data, train an imitation learning model, and encrypt that model using Wave, respectively. \n",
    "\n",
    "The preprocessing function reads an input CSV and converts the `up`, `down`, and `stay` labels into numerical values. It also normalizes the all the numerical values (the location of the controlled paddle, the location & velocity of the ball, and the previous location of the ball)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-DEFINED FLOR FUNCTION. PLEASE DO NOT CHANGE.\n",
    "\n",
    "@flor.func\n",
    "def preproc_imitation(imitation_data, procd_imitation_data, **kwargs):\n",
    "    import pandas as pd\n",
    "    df_data = pd.read_csv(imitation_data)\n",
    "    \n",
    "    # drop the user column because we don't want to train on it\n",
    "    df_data = df_data.drop(labels=\"user\", axis=1)\n",
    "\n",
    "    # discretize the labels\n",
    "    def convert_label(label):\n",
    "        \"\"\"Convert labels into numeric values\"\"\"\n",
    "        if(label==\"down\"):\n",
    "            return 1\n",
    "        elif(label==\"up\"):\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df_data['label'] = df_data['label'].apply(convert_label)\n",
    "    df_data.loc[:, \"leftPaddle_y\":\"ball_y_prev\"] = df_data.loc[:, \"leftPaddle_y\":\"ball_y_prev\"]/500.0\n",
    "    df_data.to_json(procd_imitation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model training function takes a JSON blob of the cleaned data and fits a SciKit Learn logistic regression model to classify the action to take based on the input features. The model is pickled and dumped into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-DEFINED FLOR FUNCTION. PLEASE DO NOT CHANGE.\n",
    "\n",
    "@flor.func\n",
    "def train_imitation_model(procd_imitation_data, model, **kwargs):\n",
    "    import cloudpickle\n",
    "    import pandas as pd\n",
    "    from sklearn import linear_model\n",
    "    df_data = pd.read_json(procd_imitation_data)\n",
    "    \n",
    "    labels = df_data['label']\n",
    "    training_data= df_data.drop(['label'], axis=1)\n",
    "\n",
    "    skmodel = linear_model.LogisticRegression()\n",
    "    skmodel.fit(training_data, labels)\n",
    "    with open(model, 'wb') as f:\n",
    "        cloudpickle.dump(skmodel, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `encrypt_model` function takes the model we trained above and a handle to a WAVE entity that has access to all models. It uses the WAVE entity to encrypt the model and serializes the ciphered model into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE-DEFINED FLOR FUNCTION. PLEASE DO NOT CHANGE.\n",
    "\n",
    "@flor.func\n",
    "def encrypt_model(granting_entity, model, model_tag, encrypted_model, **kwargs):\n",
    "    import wave3 as wv\n",
    "    granting_entity = deserializeEntity(granting_entity)\n",
    "    \n",
    "    # read the model binary, so we can encrypt it\n",
    "    with open(model, 'rb') as f:\n",
    "        model = f.read()\n",
    "    \n",
    "    # NOTE: We are relying on a global handle to WAVE here. \n",
    "    # In practice, we would have to recreate this handle explicitly.\n",
    "    encrypt_response = wave.EncryptMessage(\n",
    "        wv.EncryptMessageParams(\n",
    "            # the namespace is the organization\n",
    "            namespace=granting_entity.hash,\n",
    "            resource=\"models/pong/\" + model_tag,\n",
    "            content=model))\n",
    "    \n",
    "    with open(encrypted_model, 'wb') as f:\n",
    "        f.write(encrypt_response.ciphertext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a Flor experiment called `pong-imitation` and link together the input data and the functions defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** RERUN ***\n",
    "\n",
    "# CHANGE ME LATER\n",
    "DATA_FILE = 'imitation-small.csv'\n",
    "\n",
    "# get the small or large tag from the DATA_FILE variable\n",
    "model_tag = DATA_FILE.split('.')[0].split('-')[1]\n",
    "\n",
    "# where to serialize the deserialize the Wave entity\n",
    "ENTITY_FILE = 'org_entity.bin'\n",
    "\n",
    "with flor.Experiment('pong-imitation') as ex:\n",
    "    # load data into an artifact\n",
    "    imitation_data = ex.artifact(DATA_FILE, 'imitation_data')\n",
    "    \n",
    "    # call preprocessing function\n",
    "    do_preproc_imitation = ex.action(preproc_imitation, [imitation_data])\n",
    "    procd_imitation_data = ex.artifact('imitation_data.json', 'procd_imitation_data', do_preproc_imitation)\n",
    "    \n",
    "    # train the model \n",
    "    do_train_imitation_model = ex.action(train_imitation_model, [procd_imitation_data])\n",
    "    model = ex.artifact('model.pkl', 'model', do_train_imitation_model)\n",
    "    \n",
    "    model_tag = ex.literal(name='model_tag', v=model_tag)\n",
    "    \n",
    "    # serialize the wave entity, so we can track it as an artifact\n",
    "    serializeEntity(orgEntity, ENTITY_FILE)\n",
    "    granting_entity = ex.artifact(ENTITY_FILE, 'granting_entity')\n",
    "    \n",
    "    do_encrypt_model = ex.action(encrypt_model, [granting_entity, model, model_tag])\n",
    "    encrypted_model = ex.artifact('encrypted_model.bin', 'encrypted_model', do_encrypt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will call `pull` on the encrypted model. As we saw in the Flor tutorial, this will run the whole pipeline and generate the model. The `utag` argument will be used to differentiate from different versions of the model we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** RERUN ***\n",
    "\n",
    "encrypted_model.pull(utag=model_tag)\n",
    "model_location = encrypted_model.resolve_location()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model that we've trained, we are going to deploy it in Clipper. Run the cell below to start Clipper on your EC@ instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make logging work correctly in the Jupyter notebook and set up Clipper\n",
    "# NOTE: YOU SHOULD ONLY RUN THIS CELL ONCE!\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "from clipper_admin import DockerContainerManager, ClipperConnection\n",
    "from clipper_admin.deployers import python as py_deployer\n",
    "from clipper_util.auth_deployer import auth_deploy_python_model\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "clipper_conn = ClipperConnection(DockerContainerManager())\n",
    "clipper_conn.stop_all()\n",
    "clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now read the encrypted model from the file Flor has stored it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** RERUN ***\n",
    "\n",
    "# load the encrypted model into memory\n",
    "with open(model_location, 'rb') as f:\n",
    "    ciphered_model = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will attempt to deploy that model. You'll notice that we've wrapped the standard Clipper API with a special authenticated deployer that only deploys the model if it can decrypt it with the given recipient entity.\n",
    "\n",
    "Running the cell below _*should initially fail*_. This is because we haven't yet granted the `recipientEntity` permission to read the model that we've encrypted. Run the cell below to see for yourself.\n",
    "\n",
    "Once we deploy the model, we will create a new application called `pong-{model_name}` and link the model to that application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** RERUN ***\n",
    "\n",
    "model_name = \"pong-policy-\" + model_tag.v\n",
    "app_name = \"pong-\" + model_tag.v\n",
    "\n",
    "auth_deploy_python_model(\n",
    "    clipper_conn,\n",
    "    model_name,\n",
    "    wave,\n",
    "    recipientEntity,\n",
    "    ciphered_model,    \n",
    "    version=1,\n",
    "    input_type=\"doubles\"\n",
    ")\n",
    "\n",
    "clipper_conn.register_application(name=app_name, default_output=\"0\", input_type=\"doubles\", slo_micros=100000)\n",
    "clipper_conn.link_model_to_app(app_name=app_name, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to go ahead and use the helper function defined above to grant permission to the recipient entity to decrypt the ciphered model. Run the cell below to grant decryption permission then rerun the cell above to build and deploy the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** RERUN ***\n",
    "\n",
    "grantPermission(orgEntity, recipientEntity, 'models/pong/' + model_tag.v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for comparison's sake, we're going to train another imitation learning model with a different dataset -- `imitation-large.csv`. This dataset incorporates training data from two different players, and it should ideally perform better than the previous version. \n",
    "\n",
    "In the Flor experiment cell above, change the `DATA_FILE` variable to point to `imitation-large.csv` and then rerun all the calls marked with `# *** RERUN ***`. \n",
    "\n",
    "Once you've done that, run the cell below to start the pong server locally, and you'll be given a URL which you can open in your browser to play against the two pong models you've just trained. You'll select the models as opponents in the dropdown menu on the left hand side. You'll notice there's a reinforcement learning option there as well -- we'll come back to that model soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipper_addr = clipper_conn.get_query_addr()\n",
    "\n",
    "import subprocess\n",
    "server_handle = subprocess.Popen([\"./start_webserver.sh\", clipper_addr], stdout=subprocess.PIPE)\n",
    "print(str(server_handle.stdout.readline().strip(), 'utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that, surprisingly, the model trained on the large dataset performs significantly worse than the model trained on the small dataset. Let's take a look at the difference between the two and see why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the two CSVs into dataframes\n",
    "import pandas as pd\n",
    "large = pd.read_csv('imitation-large.csv')\n",
    "small = pd.read_csv('imitation-small.csv')\n",
    "\n",
    "large[large.merge(small, on=list(large.columns), how='left', indicator=True)['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all the entries in the large dataset have been made by Ion, who apparently isn't very good at Pong. As a result, the noise from these entries worsens the performance of the model in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will use Proximal Policy Optimization (PPO) to train a reinforcement learning agent that plays Pong. As we'll see, the RL policy trained here will perform significantly better than either of the imtiation learning models we trained above. As with the previous exercise, we'll first define a couple Flor functions. We will also reuse the encrypt model function defined above.\n",
    "\n",
    "First, we need to either start Ray or make sure it's already running on our machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def start_ray(**kwargs):\n",
    "    try:\n",
    "        ray.get([])\n",
    "    except:\n",
    "        ray.init()    \n",
    "    return {'exit_code': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function called Train agent that takes an environment configuration and trains the model for a specified number of iterations. Both the environment config and the number of iterations will be Flor literals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def train_agent(env_config, num_iterations, model, **kwargs):\n",
    "    import cloudpickle as cp\n",
    "    \n",
    "    register_env(\"pong_env\", lambda ec: pong_py.PongJSEnv())\n",
    "    agent = ppo.PPOAgent(env=\"pong_env\", config={\"env_config\": {}})\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        result = agent.train()\n",
    "        \n",
    "    with open(model, 'wb') as f:\n",
    "        f.write(agent.save_to_object())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll string all of these functions together into another Flor experiment called `rl-pong`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = 'rl'\n",
    "\n",
    "with flor.Experiment('rl-pong') as ex:\n",
    "    # make sure that Ray is running before attempting to train a model\n",
    "    do_start_ray = ex.action(start_ray, [])\n",
    "    exit_code = ex.literal(name='exit_code', parent=do_start_ray)\n",
    "    \n",
    "    # define configurations variables relevant to training the RL model\n",
    "    env_config = ex.literal({}, 'env_config') # TODO: Fill env_config\n",
    "    num_iterations = ex.literal(50, 'num_iterations')\n",
    "\n",
    "    # setup the training action and the save location of the checkpoint\n",
    "    do_train_agent = ex.action(train_agent, [env_config, num_iterations, exit_code])\n",
    "    model = ex.artifact('model.pkl', 'model', do_train_agent)\n",
    "    \n",
    "    model_tag = ex.literal(name='model_tag', v=model_tag)\n",
    "    \n",
    "    # serialize the wave entity, so we can track it as an artifact\n",
    "    serializeEntity(orgEntity, ENTITY_FILE)\n",
    "    granting_entity = ex.artifact(ENTITY_FILE, 'granting_entity')\n",
    "    \n",
    "    do_encrypt_model = ex.action(encrypt_model, [granting_entity, model, model_tag])\n",
    "    encrypted_model = ex.artifact('encrypted_model.bin', 'encrypted_model', do_encrypt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run this pipeline in the usual fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_model.pull()\n",
    "model_location = encrypted_model.resolve_location()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we have to grant permission to the entity to decrypt the model, but this time, we'll use a wildcard, letting it decrypt anything in the `models/pong/` resource space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grantPermission(orgEntity, recipientEntity, 'models/pong/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And deploy the model to Clipper under a new application name (`pong-rl`). Note that this code is the same as the cell above but is repeated for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clipper_util.auth_deployer import auth_deploy_rllib_model\n",
    "\n",
    "# load the encrypted model into memory\n",
    "with open(model_location, 'rb') as f:\n",
    "    ciphered_model = f.read()\n",
    "\n",
    "model_name = \"pong-policy-\" + model_tag.v\n",
    "app_name = \"pong-\" + model_tag.v\n",
    "\n",
    "auth_deploy_rllib_model(\n",
    "    clipper_conn,\n",
    "    model_name,\n",
    "    wave,\n",
    "    recipientEntity,\n",
    "    ciphered_model,    \n",
    "    version=1,\n",
    "    input_type=\"doubles\"\n",
    ")\n",
    "\n",
    "clipper_conn.register_application(name=app_name, default_output=\"0\", input_type=\"doubles\", slo_micros=100000)\n",
    "clipper_conn.link_model_to_app(app_name=app_name, model_name=model_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
